from bs4 import BeautifulSoup
import urllib.request
import json

url = "http://adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=19209&r=&rc=1"

webpage = urllib.request.urlopen(url)
soup = BeautifulSoup(webpage.read())

title = soup.findAll('title')
table = soup.findAll('table')
poemTableRows = table[5].findAll('tr')
era = table[3].findAll('a')[1].text

#fw = open("write.txt","w")

authorAndTitle = title[0].text
authorAndTitle = authorAndTitle.split(':')

author = authorAndTitle[0].strip()
name = authorAndTitle[1].strip()
author = author[8:]

poem = {"title":name, "author":author, "era":era, "abyat":[]}

for row in poemTableRows:
    col = row.findAll('td')
    sudr = col[0].text
    ajz = col[-1].text
    poem["abyat"].append({"sadr":sudr, "ajez":ajz})
    #fw.write(sudr +"        "+ ajz + "\n")

with open("poem.json","w") as outfile:
    json.dump(poem, outfile, ensure_ascii=False)



#fw.write(author + "\n")
#fw.write(name + "\n")
#fw.close()




#vvvvvv DISREGARD THE BELOW vvvvvv

#use table[4] for poem number if needed.
# Trim off the table header row
#tablerows = commodittTableRows[1:]

#for line in soup.findAll('a'):
 #   print(line.get('href'))
 #above prints links on page nicely! maybe solve the arabic letter problem!!



#NOTE: requests module doesnt read data that is in arabic, urllib does. that is why the links obtained in masscrap were retarted, cause the arabic letter was changed to something else!


#print(soup('table')[5].findAll('tr')[1].findAll('td')[1].string)

#print(soup('table')[6].prettify())

#poems = soup.findAll('td',{'class':'poem'})
#poems = soup.findAll('td')

#for eachpoem in poems:
    #print(eachpoem.string)
